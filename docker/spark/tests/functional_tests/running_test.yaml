# Copyright 2022 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

setup:
- command:
  - docker
  - run
  - '-d'
  - '-e'
  - SPARK_LOCAL_IP=spark-$UNIQUE-master
  - '-e'
  - SPARK_WORKLOAD=master
  - -p
  - 127.0.0.1:9090:9090
  - -p
  - 127.0.0.1:7077:7077
  - --name
  - spark-$UNIQUE-master
  - "$IMAGE"
- command: ["sleep", "10s"]
- command:
  - docker
  - run
  - -d
  - -e
  - SPARK_MASTER=spark://spark-$UNIQUE-master:7077
  - -e
  - SPARK_WORKER_CORES=1
  - -e
  - SPARK_WORKER_MEMORY=1G
  - -e
  - SPARK_DRIVER_MEMORY=1G
  - -e
  - SPARK_EXECUTOR_MEMORY=1G
  - -e
  - SPARK_WORKLOAD=worker
  - -e
  - SPARK_LOCAL_IP=spark-$UNIQUE-worker-a
  - --name
  - spark-$UNIQUE-worker-a
  - -p
  - 127.0.0.1:9091:8080
  - -p
  - 127.0.0.1:7001:7000
  - "$IMAGE"
- command:
  - docker
  - run
  - -d
  - -e
  - SPARK_MASTER=spark://spark-$UNIQUE-master:7077
  - -e
  - SPARK_WORKER_CORES=1
  - -e
  - SPARK_WORKER_MEMORY=1G
  - -e
  - SPARK_DRIVER_MEMORY=1G
  - -e
  - SPARK_EXECUTOR_MEMORY=1G
  - -e
  - SPARK_WORKLOAD=worker
  - -e
  - SPARK_LOCAL_IP=spark-$UNIQUE-worker-b
  - --name
  - spark-$UNIQUE-worker-b
  - -p
  - 127.0.0.1:9092:8080
  - -p
  - 127.0.0.1:7002:7000
  - "$IMAGE"
- command: [sleep, 5s]


teardown:
- command: [docker, stop, spark-$UNIQUE-master, spark-$UNIQUE-worker-a, spark-$UNIQUE-worker-b]
- command: [docker, rm, spark-$UNIQUE-master, spark-$UNIQUE-worker-a, spark-$UNIQUE-worker-b]

target: spark-$UNIQUE-master
tests:
- name: Create successfully "mycollection"
  command:
  - /opt/spark/bin/spark-submit
  - --master spark://spark-$UNIQUE-master:7077
  - --driver-memory 1G
  - --executor-memory 1G
  - --/opt/spark-apps/test_job.py
  expect:
    stdout:
      contains: "PySpark Partition Example"

- name: Ping successfully "mycollection"
  command: [curl, -L, "http://spark-$UNIQUE-master:9090"]
  expect:
    stdout:
      contains: '<li><strong>Alive Workers:</strong> 2</li>'
